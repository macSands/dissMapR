```r
---
title: "dissMapR Tutorial"
author: "Your Name"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

# dissMapR Tutorial

This document outlines a step-by-step workflow for analyzing compositional dissimilarity and bioregionalization using **dissMapR**.  
All code chunks below illustrate how one might implement each step in R, using various commonly used packages (e.g., `sf`, `terra`, `dplyr`, `ggplot2`, etc.).  
Please note that paths to data, package names, or exact functions may need adjustment depending on your local setup.

---

## 1. User-Defined Area of Interest and Grid Resolution

```r
# ---- 1a_Libraries ----
# Load necessary libraries
library(sf)      # for vector spatial data
library(terra)   # for raster/grid operations
library(dplyr)   # for data manipulation
library(ggplot2) # for plotting

# ---- 1b_Define_AOI ----
# 1. Define the AOI (e.g., using a shapefile 'rsa.shp')
# Adjust the path and layer name as needed
aoi <- st_read("path/to/rsa.shp")

# 2. Grid Resolution (e.g., 0.5 degrees)
grid_res <- 0.5

# ---- 1c_Generate_Grid ----
# Create a blank raster template with the desired resolution covering the AOI
# We'll use terra::rast() and the extent (bounding box) from 'aoi'
r_template <- rast(ext(aoi), resolution = grid_res, crs = st_crs(aoi)$wkt)

# Convert raster cell centroids to a data frame (x = longitude, y = latitude)
xy <- as.data.frame(crds(r_template))
colnames(xy) <- c("x", "y")

# Optional: clip out grid cells that fall outside the AOI boundary
# Convert xy -> sf -> spatial filter
xy_sf <- st_as_sf(xy, coords = c("x", "y"), crs = st_crs(aoi))
xy_aoi <- xy_sf[aoi, ]  # intersection
xy <- st_drop_geometry(xy_aoi)

# ---- 1d_Map_AOI_Grid ----
# Quick visualization: AOI + centroid points
ggplot() +
  geom_sf(data = aoi, fill = "lightgray", color = "black") +
  geom_point(data = xy, aes(x = x, y = y), color = "blue", size = 1) +
  ggtitle("Area of Interest with 0.5° Grid") +
  theme_minimal()
```

**Outcome**:  
- A map of the AOI with 0.5° grid cells  
- A data frame `xy` containing centroid coordinates for each site (grid cell)

---

## 2. Site-by-Species Matrix and Sampling Effort

```r
# ---- 2a_Occurrence_Data ----
# Suppose you have occurrence data with fields: species, longitude, latitude
# (e.g., from GBIF, local CSV, etc.). We'll simulate for demonstration.

occ_data <- data.frame(
  species = sample(c("SpeciesA", "SpeciesB", "SpeciesC"), 1000, replace = TRUE),
  decimalLongitude = runif(1000, min(st_bbox(aoi)["xmin"]), max(st_bbox(aoi)["xmax"])),
  decimalLatitude  = runif(1000, min(st_bbox(aoi)["ymin"]), max(st_bbox(aoi)["ymax"]))
)

# Assign each record to a grid cell based on coordinates:
# Convert 'xy' to a raster to facilitate cell lookups
r_id <- r_template
values(r_id) <- 1:ncell(r_id)  # each cell gets a unique ID

# Convert occurrence data to SpatVector (terra) for cell lookups
occ_vect <- vect(occ_data, geom = c("decimalLongitude", "decimalLatitude"), crs = crs(r_template))

# Identify cell ID for each occurrence
cell_ids <- cellFromXY(r_id, geom(occ_vect)[, c("x", "y")])
occ_data$cell_id <- cell_ids

# Filter out occurrences that fall outside the defined AOI grid
occ_data <- subset(occ_data, !is.na(cell_id))

# ---- 2b_Sampling_Effort ----
# Count number of occurrences per cell as a measure of sampling effort
effort_df <- occ_data %>%
  group_by(cell_id) %>%
  summarise(n_occurrences = n())

# Rasterize sampling effort (optional for mapping)
sam_eff_rast <- r_id
values(sam_eff_rast) <- 0
values(sam_eff_rast)[effort_df$cell_id] <- effort_df$n_occurrences

# ---- 2c_Site_by_Species_Matrix ----
# For presence-absence, pivot occurrence data to wide format:
library(tidyr)

sbs_long <- occ_data %>%
  distinct(cell_id, species) %>%
  mutate(presence = 1)

# Ensure we have a row for every cell (site) in 'xy'
all_cells <- data.frame(cell_id = 1:ncell(r_id))
sbs_wide <- all_cells %>%
  left_join(sbs_long, by = "cell_id") %>%
  pivot_wider(id_cols = cell_id, names_from = species, values_from = presence, values_fill = 0)

# sbs - site-by-species matrix
sbs <- as.data.frame(sbs_wide[ , -1])  # remove cell_id column
row.names(sbs) <- sbs_wide$cell_id

# Summarize sampling effort in a vector aligned with sbs rows
sam.eff <- numeric(nrow(sbs))
sam.eff[effort_df$cell_id] <- effort_df$n_occurrences

# ---- 2d_Optional_Maps ----
# Species richness map (row sums of sbs)
richness <- rowSums(sbs)
richness_rast <- r_id
values(richness_rast) <- 0
values(richness_rast)[as.numeric(names(richness))] <- richness

# Quick plot of sampling effort + species richness
plot(sam_eff_rast, main = "Sampling Effort")
plot(richness_rast, main = "Species Richness")
```

**Outcome**:  
- **sbs**: binary presence–absence (site-by-species)  
- **sam.eff**: numeric sampling effort per site  
- Optional raster maps for sampling effort and species richness

---

## 3. Site-by-Environment Matrix

```r
# ---- 3a_Environmental_Data ----
# Assume we have environmental rasters (temp, precip, etc.) with same CRS and extent
# Here we just simulate them:
env1 <- r_template; values(env1) <- runif(ncell(r_template), min = 10, max = 30)  # e.g., temperature
env2 <- r_template; values(env2) <- runif(ncell(r_template), min = 100, max = 3000) # e.g., precipitation

# Combine into a SpatRaster
env_stack <- c(env1, env2)
names(env_stack) <- c("temp", "precip")

# ---- 3b_Extract_Env_Values ----
# Extract environmental values at each site centroid
env_vals <- extract(env_stack, cbind(xy$x, xy$y))
env_vals <- env_vals[ , -1]  # remove ID column returned by extract()

# ---- 3c_Build_sbe ----
# Combine environment variables + sampling effort into one data frame
sbe <- cbind(env_vals, sam.eff)  # site-by-environment, includes sampling effort
colnames(sbe) <- c("temp", "precip", "sam.eff")

# We'll also update the env_stack to include sampling effort if desired
sam_eff_raster <- sam_eff_rast
names(sam_eff_raster) <- "sam.eff"
env_stack_all <- c(env_stack, sam_eff_raster)
```

**Outcome**:  
- **sbe**: site-by-environment matrix (including sampling effort)  
- Updated raster stack (`env_stack_all`) with environment layers + sampling effort

---

## 4. Zeta Decline and Zeta Decay

```r
# ---- 4a_Zeta_Decline ----
# We'll assume dissMapR or zetadiv provides functions for multi-site zeta.
# For example, using the 'zetadiv' package:
library(zetadiv)

# sbs must be a site-by-species matrix (rows=sites, columns=species)
zeta_orders <- 2:15

zeta.decline <- Zeta.decline.ex(
  data.spec = sbs, orders = zeta_orders,
  sam = 100, # number of random site subsets for estimation
  plot = FALSE
)

# Plot zeta decline
plot(zeta_orders, zeta.decline$zeta.val, type = "b",
     xlab = "Order", ylab = "Mean Zeta Diversity",
     main = "Zeta Decline")

# ---- 4b_Zeta_Decay ----
# Evaluate how zeta diversity changes with distance
# We need site coordinates (xy) + species (sbs)
zeta.decay <- Zeta.decline.xy(
  data.spec = sbs, xy = as.matrix(xy), orders = 2,
  distance.type = "Euclidean",
  plot = FALSE
)

# Plot zeta decay vs. distance
plot(zeta.decay$distance, zeta.decay$zeta.val, pch = 16,
     xlab = "Distance", ylab = "Zeta (Order=2)",
     main = "Zeta Decay with Distance")
```

**Outcome**:  
- Measures of **zeta decline** across orders  
- Measures of **zeta decay** with distance  
- Plots illustrating these relationships

---

## 5. MS-GDM with `Zeta.msgdm(sbs, sbe, xy)`

```r
# ---- 5a_Fit_MultiSite_GDM ----
# We now assume dissMapR has a function Zeta.msgdm() for multi-site GDM
# (this is hypothetical; adapt based on actual package usage)

library(dissMapR)  # hypothetical package

# Fit MS-GDM for orders = 2, 3, 5, 10
orders_to_fit <- c(2, 3, 5, 10)
msgdm_list <- list()

for (ord in orders_to_fit) {
  fit <- Zeta.msgdm(sbs = sbs, sbe = sbe, xy = xy, order = ord)
  msgdm_list[[paste0("order", ord)]] <- fit
}

# Summaries or model stats
lapply(msgdm_list, summary)

# ---- 5b_Save_Model_Order2 ----
zeta2 <- msgdm_list[["order2"]]  # store the fitted order 2 model
```

**Outcome**:  
- **zeta2**: fitted MS-GDM for order 2  
- Additional model objects for orders 3, 5, and 10

---

## 6. Prediction with `zeta2` (Present Scenario)

```r
# ---- 6a_Uniform_Sampling ----
# Replace sampling effort in 'sbe' with its maximum value
sam.max <- max(sbe$sam.eff)
sbe_now <- sbe
sbe_now$sam.eff <- sam.max

# ---- 6b_Predict_zeta2 ----
zeta.now <- predict(zeta2, newdata = sbe_now)
# zeta.now should be a site-by-site matrix of predicted dissimilarities (order=2)

# ---- 6c_Visualize_zeta_now ----
# (i) NMDS
library(vegan)
nmds_now <- metaMDS(zeta.now, k = 3, try = 20)

# Extract NMDS coordinates
nmds_coords <- as.data.frame(scores(nmds_now))
colnames(nmds_coords) <- c("NMDS1", "NMDS2", "NMDS3")

# (ii) RGB composite plot from NMDS axes
# Combine NMDS coords with site centroids 'xy'
nmds_plot_df <- cbind(xy, nmds_coords)

ggplot(nmds_plot_df, aes(x = x, y = y)) +
  geom_point(aes(color = rgb(
    scales::rescale(NMDS1),
    scales::rescale(NMDS2),
    scales::rescale(NMDS3)
  )), size = 2) +
  scale_color_identity() +
  ggtitle("Present Scenario: NMDS RGB Composite") +
  theme_minimal()

# (iii) Clustering + Bioregions
# Example: hierarchical clustering
hc_now <- hclust(as.dist(zeta.now), method = "ward.D2")
# Choose number of clusters
k <- 5
bioregions_now <- cutree(hc_now, k = k)
```

**Outcome**:  
- **zeta.now**: predicted site-by-site dissimilarity matrix under uniform sampling  
- NMDS-based RGB map  
- Bioregional clusters (e.g., 5 clusters)

---

## 7. Prediction with `zeta2` (Future Scenarios)

```r
# ---- 7a_Prepare_Future_Env ----
# Suppose we have m future scenarios for environment (temp, precip).
# We'll combine them so that all scenarios + present are in one large sbe data frame.

# Create a placeholder example for 2 future scenarios
env1_future1 <- env1; values(env1_future1) <- values(env1_future1) + 2
env2_future1 <- env2; values(env2_future1) <- values(env2_future1) + 100

env1_future2 <- env1; values(env1_future2) <- values(env1_future2) + 4
env2_future2 <- env2; values(env2_future2) <- values(env2_future2) + 200

# Extract for each scenario
env_vals_future1 <- extract(c(env1_future1, env2_future1), cbind(xy$x, xy$y))[, -1]
env_vals_future2 <- extract(c(env1_future2, env2_future2), cbind(xy$x, xy$y))[, -1]

# Combine into data frames, reusing sam.max
sbe_future1 <- cbind(env_vals_future1, sam.eff = sam.max)
colnames(sbe_future1) <- c("temp", "precip", "sam.eff")

sbe_future2 <- cbind(env_vals_future2, sam.eff = sam.max)
colnames(sbe_future2) <- c("temp", "precip", "sam.eff")

# Combine present (sbe_now) + 2 future scenarios:
sbe_all <- rbind(sbe_now, sbe_future1, sbe_future2)

# ---- 7b_Predict_Future ----
zeta.future <- predict(zeta2, newdata = sbe_all)
# This will be a ((m+1)*n x (m+1)*n) dissimilarity matrix
# where m=2 (two future scenarios), n=number of sites

# ---- 7c_Visualize_Future ----
# We can subset 'zeta.future' to map each scenario individually
# For example, the first 'n' rows/cols = present, next 'n' = future1, last 'n' = future2
n_sites <- nrow(sbe_now)
present_idx   <- 1:n_sites
future1_idx   <- (n_sites+1):(2*n_sites)
future2_idx   <- (2*n_sites+1):(3*n_sites)

zeta.present  <- zeta.future[present_idx, present_idx]
zeta.fut1     <- zeta.future[future1_idx, future1_idx]
zeta.fut2     <- zeta.future[future2_idx, future2_idx]

# Optionally run NMDS or clustering for each scenario
# Here, just an example with future scenario 1
nmds_fut1 <- metaMDS(zeta.fut1, k = 3, try = 20)
nmds_coords_fut1 <- as.data.frame(scores(nmds_fut1))
# (Plot similarly as above, but note the site order matches rows in future1_idx)
```

**Outcome**:  
- **zeta.future**: site-by-site predicted dissimilarities for present + multiple future scenarios  
- Tools for NMDS/clustering to map future shifts in bioregions

---

## 8. Data Publication to Zenodo

```r
# ---- 8a_Prepare_Outputs ----
# Collect your final data frames and raster objects:
#   - sbs, xy, sbe, zeta.now, zeta.future, etc.
#   - Maps (sampling effort, zeta plots, NMDS RGB maps, cluster results)
#   - Model objects (zeta2, etc.)
#
# Save them to disk as CSV, RDS, GeoTIFF, etc.
saveRDS(sbs, "sbs.rds")
saveRDS(xy, "xy.rds")
saveRDS(sbe, "sbe.rds")
saveRDS(zeta.now, "zeta_now.rds")
saveRDS(zeta.future, "zeta_future.rds")
# ... etc.

# ---- 8b_Zenodo_Upload ----
# Use zen4R or manual upload:
# install.packages("zen4R")
library(zen4R)

# Provide your Zenodo token, metadata, etc.
zenodo <- ZenodoManager$new(token = "YOUR_ZENODO_TOKEN")

# Create a new deposition, set metadata
my_deposition <- zenodo$createEmptyRecord()
my_deposition <- zenodo$setMetadata(
  my_deposition,
  title = "Multi-Site Dissimilarity Data & Models",
  upload_type = "dataset",
  description = "Data and model outputs from the dissMapR workflow.",
  creators = list(
    list(name = "Your Name", affiliation = "Your Institution")
  )
)

# Then upload files:
# zenodo$uploadFile("sbs.rds", my_deposition$id)
# zenodo$uploadFile("sbe.rds", my_deposition$id)
# etc.

# Finally, publish:
# zenodo$publishRecord(my_deposition$id)
```

**Outcome**:  
- All necessary data (e.g., `sbs`, `xy`, `sbe`, `zeta.now`, `zeta.future`, figures) are archived on Zenodo for reproducibility.  

---

# Final Remarks

- This script demonstrates the **core** steps for dissecting compositional turnover and bioregional patterns under present or future scenarios using `dissMapR` (and related packages).  
- Each step can be adapted to use your specific data sources and packages.  
- Always verify spatial extents, coordinate reference systems, and the validity of environmental data before scaling up analyses.  

```